{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSFqR7tIKJpw"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BbAVeGscKPcg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import PCA\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "#from keras import dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsO19HaMNBVL"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fgJIJnsfNEGa"
      },
      "outputs": [],
      "source": [
        "# Set the Seed\n",
        "randomSeed = 1000\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.2, random_state = randomSeed)\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10882, 59)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Initialising the ANN\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(32, activation = 'relu', input_dim = 59))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(units = 32, activation = 'relu', activity_regularizer=regularizers.l2(0.01), \n",
        "                kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Add a dropout layer\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "model.add(Dense(units = 32, activation = 'relu', activity_regularizer=regularizers.l2(0.01), \n",
        "                kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "#best: lr= 0.01, batch_size = 10, epochs = 30, one dropout layer between 2 and 3\n",
        "# Compiling the ANN\n",
        "model.compile(optimizer = optimizers.Adam(learning_rate=0.01), loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model.fit(X_train, y_train, batch_size = 10, epochs = 40)\n",
        "\n",
        "y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45480.466272972415"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#convert y_pred to 1D array\n",
        "y_pred = y_pred.flatten()\n",
        "np.sqrt(np.mean((y_test - y_pred)**2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CV for NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "\n",
        "#get the path to all csv files in the folder final_data_files\n",
        "all_filenames = ['final_data_files/2_df_man.csv', 'final_data_files/3_df_man_PCA.csv', 'final_data_files/4_df_man_noNanCat.csv', \n",
        "                 'final_data_files/5_df_freq.csv', 'final_data_files/6_df_freq_PCA.csv', 'final_data_files/7_df_freq_noNanCat.csv']\n",
        "\n",
        "results_rmse = []\n",
        "results_mae = []\n",
        "for i in range(len(all_filenames)):\n",
        "    data_x = pd.read_csv(all_filenames[i], sep=',', index_col=0).drop(['Price'], axis=1)\n",
        "    data_y = pd.read_csv(all_filenames[i], sep=',', index_col=0)['Price']\n",
        "\n",
        "    rmse_list = []\n",
        "    mae_list = []\n",
        "    kFold = KFold(n_splits=5, shuffle=True, random_state= randomSeed)\n",
        "    for train_index, test_index in kFold.split(data_x):\n",
        "        X_train, X_test = data_x.iloc[train_index], data_x.iloc[test_index]\n",
        "        y_train, y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
        "\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.transform(X_test)\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # Adding the input layer and the first hidden layer\n",
        "        model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n",
        "\n",
        "        # Adding the second hidden layer\n",
        "        model.add(Dense(units = 32, activation = 'relu', activity_regularizer=regularizers.l2(0.01), \n",
        "                        kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "        # Add a dropout layer\n",
        "        #model.add(Dropout(0.1))\n",
        "\n",
        "        # Adding the third hidden layer\n",
        "        model.add(Dense(units = 32, activation = 'relu', activity_regularizer=regularizers.l2(0.01), \n",
        "                        kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "        # Adding the output layer\n",
        "        model.add(Dense(units = 1))\n",
        "\n",
        "        #second best: lr= 0.01, batch_size = 10, epochs = 30, one dropout layer between 2 and 3\n",
        "        # Compiling the ANN\n",
        "        model.compile(optimizer = optimizers.Adam(learning_rate=0.01), loss = 'mean_squared_error')\n",
        "\n",
        "        # Fitting the ANN to the Training set\n",
        "        model.fit(X_train, y_train, batch_size = 10, epochs = 40)\n",
        "\n",
        "        # Make predictions on the testing set\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Calculate and save the RMSE for this fold\n",
        "        mse = mean_squared_error(y_test, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        rmse_list.append(rmse)\n",
        "\n",
        "        # Calculate and save the MAE for this fold\n",
        "        mae = mean_absolute_error(y_test, predictions)\n",
        "        mae_list.append(mae)\n",
        "\n",
        "    results_rmse.append(np.mean(rmse_list))\n",
        "    results_mae.append(np.mean(mae_list))    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[48295.01745793575, 48443.51129358997, 49463.290206533406, 63589.41982246747, 48277.07436660505, 53440.640553125704]\n",
            "[28265.59456568516, 29015.693331531358, 28473.937515026133, 29326.47570930196, 28780.204483842168, 29235.305308654293]\n"
          ]
        }
      ],
      "source": [
        "print(results_rmse)\n",
        "print(results_mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMzKGj+h8S7KY/ffJxXo2da",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
